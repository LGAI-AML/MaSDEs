<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<script type="text/x-mathjax-config">
        MathJax.Hub.Config({            
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}            
        });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>

<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<!-- <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}

h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}

h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #015104;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}


.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}

.equal_cont {
    font-size: 12px;
}

.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}

.eqno {
    text-align: left;
}

.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}

.paper-btn2 {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 18px;
  width: 120px;
  font-weight: 600;
}

.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #ffffff;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    display: block;
    margin-left: auto;
    margin-right: auto;
    align-items: center;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}


/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}

/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
    <title> Neural Stochastic Differential Games for Time-series Analysis</title>
</head>

<body>
<div class="topnav" id="myTopnav">
    <div>
        <a href="https://www.lgresearch.ai/"><img width="60%" src="assets/LG_AI.png"></a>
    </div>
</div>
  
<div class="paper-title">
    <h1> 
        Neural Stochastic Differential Game <br> for Time-Series Analysis </h1>
    </div>

      <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://scholar.google.co.kr/citations?user=B1xpjO8AAAAJ&hl=en">Sungwoo Park<sup>* 1</sup></a>,
                <a href="https://scholar.google.com/citations?user=MWCPYLMAAAAJ&hl=en">Byoungwoo Park<sup>* 3</sup></a>,
                <a href="https://scholar.google.com/citations?user=BMvYy9cAAAAJ&hl=en">Moontae Lee<sup>1,2</sup></a>,
                <a href="https://scholar.google.com/citations?user=kSvJTg4AAAAJ&hl=en">Changhee Lee<sup>3</sup></a>        
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span><sup>1</sup> LG AI Reasearch</span>
            <span><sup>2</sup> University of Illinois Chicago</span>
            <span><sup>3</sup> Chung-Ang University</span> <br/>
        </div>
        <div class="equal-cont">
            <span><sup>*</sup> Equal contribution</span>
        </div>

        <div class="affil-row">
            <div class="venue text-center"><b>ICML 2023 </b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://drive.google.com/file/d/1R2GO5Uh8cOol_OtIPSX0XMbD57_iJTFq/view?usp=sharing">
                <!-- <span class="material-icons"> Paper </span> -->
                Paper
            </a>
            <a class="paper-btn2" href="https://openreview.net/forum?id=Z1kD2xOpVl">
                <!-- <span class="material-icons"> open-review </span> -->
                OpenReview
            </a>            
            <div class="paper-btn-coming-soon">
                <a class="paper-btn" href="https://github.com/parks-research/multi_agent_sdes">
                    <!-- <span class="material-icons"> Code </span> -->
                    Code
                </a>
            </div>
        </div></div>
    </div>

    <section id="abstract"/>
    <hr>
    <h2>Abstract</h2>
    <div class="flex-row">
        <p> Modeling spatiotemporal dynamics with neural differential equations has become a major line of research that opens new ways to handle 
            various real-world scenarios (eg., missing observations, irregular times, etc.). Despite such progress, most existing methods 
            still face challenges in providing a general framework for analyzing time series. To tackle this, we adopt stochastic differential games 
            to suggest a new philosophy of utilizing interacting collective intelligence in time series analysis. For the implementation, we develop 
            the novel gradient descent-based algorithm called deep neural fictitious play to approximate the Nash equilibrium. 
            We theoretically analyze the convergence result of the proposed algorithm and discuss the advantage of cooperative games 
            in handling noninformative observation. Throughout the experiments on various datasets, we demonstrate the superiority of our framework 
            over all the tested benchmarks in modeling time-series prediction by capitalizing on the advantages of applying cooperative games. 
            An ablation study shows that neural agents of the proposed framework learn intrinsic temporal relevance to make accurate time-series predictions.
        </p>
    </div>
    </section>
 
    <section id="method"/>
        <hr>
        <h2>Method</h2>
        <center>
            <figure style="width: 100%;">
                    <a>
                        <img width="95%" src="assets/main_figure.png"> 
                    </a>
                    <p class="caption" style="margin-bottom: 24px;"><br>
                        Each agent individually encodes the impact of a partial observation into an underlying stochastic trajectory 
                        and interacts with each other to extract meaningful information to predict the future. 
                        We formulate the collaboration among agents from the view of cooperative differential game to intergrate the
                        individual information and adaptively balance the importance of each agent. As a results of the differential game,
                        cooperative agents achieve the Nash equilibrium and agree to suppress non-informative observations and highlight the
                        contribution of important observations for accurate prediction.
                    </p>
            </figure>

        </center>
        <div class="flex-row">
            <p> 
                We present a novel framework built upon a game theory to model 
                temporal dynamics of time-series data. More specifically, we extend the conventional differential equation (DE) 
                to the multi-agent counterpart for decomposing the observational time-series.
                To the best of our knowledge, this work is the first attempt to adopt a philosophy of game theory 
                in dealing with multivariate time-series. For tractability of applying differential games, 
                we propose a novel gradient descent-based algorithm called deep neural fictitious play, which operates 
                in a tractable and parallel way to obtain the Nash equilibrium. Theoretical results based on the 
                Feynman-Kac formalism follow to guarantee the convergence of the proposed algorithm and explicate 
                the temporal relevance of past and future. Our approach includes the following crucial components:
            </p>

            <p>
                <b>Multi-conditioned Score-based Predictor:</b> Since each neural agent can only represent the individual impact 
                of partial information, we aggregate the individual decisions made by each neural agent to capitalize on 
                the temporal dynamics available from the entire set of past observations. 
                Inspired by recent work <a href="https://arxiv.org/abs/2011.13456"><b>Score-based generative model</b></a> (SGM),
                we introduce the multi-conditioned score-based predictor that produces the collaborative prediction between neural agents:
            </p>

            <p>
                <b>Stochastic Differential Game:</b> To achieve efficient coordination among interacting agents and optimize 
                temporal aggregation, it's essential to have a unified structure that can effectively extract useful information 
                from time-series data. To meet these needs, we propose a novel framework that formulates the time-series prediction problem as a 
                cooperative differential game, where each neural agent balances its individual costs to achieve a Nash equilibrium:
            </p>

            <p>
                <b>Deep Neural Fictitious Play:</b> Our approach to approximating the Nash equilibrium involves a gradient descent based fictitious play algorithm with 
                Forward-Backward Stochastic differential equations (FBSDEs). This allows us to make use of neural network models for control agents, which offer sufficient expressivity for the task at hand. 
                By approximating the solution to non-convex HJBEs that support the neural network structure, we are able to successfully find the Nash equilibrium. 
                Furthermore, under our proposed training scheme, our proposed MaSDEs with a large capacity ensure small marginals to the Nash equilibrium.
            </p>

        </div>
    </section>

    <section id="results">
        <hr>
        <h2>Experiements</h2>  
        
        <h3>Synthetic Dataset</h3> 
        In the following we show the qualitative result on Mackey-Glass DDE. Since the simulated trajcetory of Mackey-Glass DDE is
        highly sensitive to the initial condition as it influence the future values in a time-delayed manner. 
        The proposed MaSDEs are able to effectively capture the long-term dependency of temporal states given past observations.
        Because the neural agents interact with each other to make cooperative decision by balancing the imporatance of decision.
        <section id="teaser-image">
            <center>
                <figure>
                    <video class="centered" width="50%" autoplay loop muted playsinline class="video-background">
                        <source src="assets/mackey.mp4#t=0.001" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <p class="caption" style="margin-bottom: 24px;"><br>
                        The highlighted region in the plane depicts the level of temporal aggregation for each deicision.
                        The vertical in the past interval represents the averaged temporal aggregation of the decision of agent
                        on the entire future interval.
                    </p>
                </figure>
            </center>
        </section>

        <hr>
        <h3>Real-word Air Quality Dataset</h3> 
        The results presented below show that neural agents under the equilibrium infer temporal decay to extract underlying 
        latent information from the dataset optimally. This phenomenon can be clearly observed at the prediction times proximate
        to the beginning of the prediction interval showing that the rational group assigns high energies while becoming less 
        distinguishable when predicting the distant future. This is remarkable since the cooperative agents reach the temporal
        decay a posterior without any prior knowledge.
        <center>
            <figure style="width: 100%;">
                    <a>
                        <img width="95%" src="assets/baqd_sample_appendix.png"> 
                    </a>
                    <p class="caption" style="margin-bottom: 24px;"><br>
                        Predictive Performance on Time-Series Features of the BAQD Dataset, 
                        Including PM${2.5}$, PM${10}$, SO$_{2}$, NO$_{2}$, CO, and O$_{3}$.
                    </p>
            </figure>
        </center>
    
        <hr>
        <h3>Point Process Signals</h3>  
        <p>
            How modeling physical phenomenon with point processes is common in various domains, 
            such as finance and geology, and how Gaussian-impulse noises can be used to mimic noisy events that 
            occur at random times. The experiment involved generating data using a homogeneous Poisson process 
            and using neural agents to accurately restore random peaks. The proposed neural agents were found to 
            learn different temporal dynamics from the data and to filter out redundant observations, which helped
            them focus on informative signals for accurate predictions.
        </p>
        
        <figure style="width: 50%;">
            <a>
                <img width="95%" src="assets/impulse_sample.png"> 
            </a>
            <p class="caption" style="margin-bottom: 24px;"><br>
                Gaussian impulse signal from a homogeneous Poisson process.
            </p>
          </figure>     
    </section> 

    <p> This webpage template was adapted from <a href="https://nv-tlabs.github.io/LION/"><b>here</b></a>. </p>
</body>
</html>
  
